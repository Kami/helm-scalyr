# Workflow which runs end to end tests against scalyr agent helm chart.
# Those tests verify that the chart can be installed and that it correctly configured agent
# ingestion for various options (daemonset mode, deployment mode, k8s cluster metrics are ingested,
# pod logs are ingested, etc.)
name: "End to End Tests"

on:
  push:
    branches:
      - master
      - main
      - end_to_end_tests
  pull_request:
    branches:
      - master
      - main
      - end_to_end_tests
  schedule:
    - cron: '0 4 * * *'

jobs:
  # Special job which automatically cancels old runs for the same branch, prevents runs for the
  # same file set which has already passed, etc.
  pre_job:
    name: Skip Duplicate Jobs Pre Job
    runs-on: ubuntu-latest
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
      - id: skip_check
        uses: fkirc/skip-duplicate-actions@f75dd6564bb646f95277dc8c3b80612e46a4a1ea # v3.4.1
        with:
          cancel_others: 'true'
          github_token: ${{ github.token }}

  daemonset_controller_type:
    needs: pre_job
    # NOTE: We always want to run job on master
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || github.ref == 'refs/heads/main' }}
    name: Daemonset Controller Type
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@18bc76811624f360dbd7f18c2d4ecb32c7b87bab # v1.1
        with:
          version: v3.7.0

      - uses: actions/setup-python@v2
        with:
          python-version: 3.7

      # NOTE: Using "kind" cluster may be preferred since it's faster to start up in some
      # situations, but for some reasons services which are started inside kind cluster can't talk
      # to the internet on GHA. Maybe DNS issue? It works just fine locally. Having said that,
      # minikube gives us more control over Kubernetes version which is indeed something we want to
      # control so we can test against multiple versions.

      # - name: Create kind Kubernetes cluster
      #   uses: helm/kind-action@94729529f85113b88f4f819c17ce61382e6d8478 # v1.2.0

      - name: Create minikube Kubernetes Cluster
        uses: manusa/actions-setup-minikube@3cce81c968cabc530141d5620b7d9942a2907df5 # v2.4.2
        with:
          #driver: "docker"
          minikube version: 'v1.23.2'
          kubernetes version: 'v1.22.2'
          #kubernetes version: 'v1.19.2'
          github token: ${{ secrets.GITHUB_TOKEN }}

      - name: Print minikube environment info
        run: |
          kubectl -n kube-system rollout restart deployment coredns
          minikube addons list
          kubectl describe deploy/coredns -n kube-system
          sleep 5

      - name: Install Scalyr tool
        run: |
          curl https://raw.githubusercontent.com/scalyr/scalyr-tool/master/scalyr > scalyr
          chmod +x scalyr
          sudo mv scalyr /usr/local/bin

      - name: Install Helm chart
        id: helm-install
        env:
          API_KEY: "${{ secrets.SCALYR_WRITE_API_KEY_US }}"
        run: |
          echo -e 'controllerType: "daemonset"\nscalyr:\n  apiKey: "'${API_KEY}'"' > ci/agent-values.yaml
          helm install --debug --wait --values ci/agent-values.yaml scalyr-agent .

          # Verify deployment does not exist for daemonset controller type
          kubectl get deployments

          # Give it some time to start up, technically there is --wait, but it
          # doesn't seem to always work
          echo "Giving pod some time to start up..."
          sleep 20

          export SCALYR_AGENT_POD_NAME=$(kubectl get pod -o jsonpath="{.items[0].metadata.name}")
          echo "SCALYR_AGENT_POD_NAME=${SCALYR_AGENT_POD_NAME}" >> ${GITHUB_ENV}

          echo "Pod logs"
          kubectl logs "${SCALYR_AGENT_POD_NAME}"

          # Give it some more time for logs to be ingested
          echo "Waiting for logs to be ingested..."
          sleep 30

      - name: Verify Agent Logs are Ingested
        env:
          scalyr_readlog_token: "${{ secrets.SCALYR_READ_API_KEY_US }}"
          SCALYR_AGENT_POD_NAME: "${{ env.SCALYR_AGENT_POD_NAME }}"
        run: |
          # Verify agent and kubernetes monitor has been started
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Starting scalyr agent..."'
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "No checkpoints were found. All logs will be copied starting at their current end"'

          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Cluster name detected, enabling k8s metric reporting"'
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "kubernetes_monitor parameters: "'

          # Verify Kubernetes metrics are beeing ingested
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/kubernetes_monitor.log" "k8s-daemon-set=\"scalyr-agent\""'

      # We install Redis helm chart and later verify that logs from Redis pods are successfully ingested
      - name: Install Redis Helm Chart
        run: |
          # We only want to spin up 1 replica to speed things up
          echo -e 'replica:\n  replicaCount: 1' > ci/redis-values.yaml

          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm install --wait --values ci/redis-values.yaml redis-test bitnami/redis

          sleep 20

      - name: Verify Redis Pods Logs are Ingested
        env:
          scalyr_readlog_token: "${{ secrets.SCALYR_READ_API_KEY_US }}"
          SCALYR_AGENT_POD_NAME: "${{ env.SCALYR_AGENT_POD_NAME }}"
        run: |
          # master pod
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "redis" pod_name="redis-test-master-0" "Redis is starting"'
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "redis" pod_name="redis-test-master-0" "Configuration loaded"'

          # replica pod
          ./ci/scripts/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "redis" pod_name="redis-test-replicas-0" "MASTER <-> REPLICA sync started"'

      # TODO: Enable once the repo has been moved
      # - name: Notify Slack on Failure
      #   # NOTE: github.ref is set to pr ref (and not branch name, e.g. refs/pull/28/merge) for pull
      #   # requests and that's why we need this special conditional and check for github.head_ref in
      #   # case of PRs
      #   if: ${{ failure() && (github.ref == 'refs/heads/main' || github.head_ref == 'main') }}
      #   uses: act10ns/slack@e4e71685b9b239384b0f676a63c32367f59c2522 # v1.2.2
      #   env:
      #     SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      #   with:
      #     status: ${{ job.status }}
      #     steps: ${{ toJson(steps) }}
      #     channel: '#cloud-tech'

  deployment_controller_type:
    needs: pre_job
    # NOTE: We always want to run job on master
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || github.ref == 'refs/heads/main' }}
    name: Deployment Controller Type
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@18bc76811624f360dbd7f18c2d4ecb32c7b87bab # v1.1
        with:
          version: v3.7.0

      - uses: actions/setup-python@v2
        with:
          python-version: 3.7

      - name: Create minikube Kubernetes Cluster
        uses: manusa/actions-setup-minikube@3cce81c968cabc530141d5620b7d9942a2907df5 # v2.4.2
        with:
          minikube version: 'v1.23.2'
          kubernetes version: 'v1.22.2'
          github token: ${{ secrets.GITHUB_TOKEN }}

      - name: Print minikube environment info
        run: |
          kubectl -n kube-system rollout restart deployment coredns
          minikube addons list
          kubectl describe deploy/coredns -n kube-system
          sleep 5

      - name: Install Scalyr tool
        run: |
          curl https://raw.githubusercontent.com/scalyr/scalyr-tool/master/scalyr > scalyr
          chmod +x scalyr
          sudo mv scalyr /usr/local/bin

      - name: Install Helm chart
        env:
          API_KEY: "${{ secrets.SCALYR_WRITE_API_KEY_US }}"
        run: |
          echo -e 'controllerType: "deployment"\nscalyr:\n  apiKey: "'${API_KEY}'"' > ci/agent-values.yaml
          helm install --debug --wait --values ci/agent-values.yaml scalyr-agent .

          # Verify deployment has been created
          kubectl get deployment scalyr-agent

          # Give it some time to start up, technically there is --wait, but it
          # doesn't seem to always work
          echo "Giving pod some time to start up..."
          sleep 20

          export POD_NAME=$(kubectl get pod -o jsonpath="{.items[0].metadata.name}")

          echo "Pod logs"
          kubectl logs "${POD_NAME}"

          # Give it some more time for logs to be ingested
          echo "Waiting for logs to be ingested..."
          sleep 40

      - name: Verify Logs are Ingested
        env:
          scalyr_readlog_token: "${{ secrets.SCALYR_READ_API_KEY_US }}"
        run: |
          export POD_NAME=$(kubectl get pod -o jsonpath="{.items[0].metadata.name}")

          # Verify agent and kubernetes monitor has been started
          ./ci/scripts/scalyr-query.sh '$serverHost="'${POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Starting scalyr agent..."'
          ./ci/scripts/scalyr-query.sh '$serverHost="'${POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "No checkpoints were found. All logs will be copied starting at their current end"'

          ./ci/scripts/scalyr-query.sh '$serverHost="'${POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Cluster name detected, enabling k8s metric reporting"'
          ./ci/scripts/scalyr-query.sh '$serverHost="'${POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "kubernetes_monitor parameters: "'

          # Verify Kubernetes metrics are beeing ingested
          ./ci/scripts/scalyr-query.sh '$serverHost="'${POD_NAME}'" $logfile="/var/log/scalyr-agent-2/kubernetes_monitor.log" "k8s-deployment=\"scalyr-agent\""'

      # TODO: Enable once the repo has been moved
      # - name: Notify Slack on Failure
      #   # NOTE: github.ref is set to pr ref (and not branch name, e.g. refs/pull/28/merge) for pull
      #   # requests and that's why we need this special conditional and check for github.head_ref in
      #   # case of PRs
      #   if: ${{ failure() && (github.ref == 'refs/heads/main' || github.head_ref == 'main') }}
      #   uses: act10ns/slack@e4e71685b9b239384b0f676a63c32367f59c2522 # v1.2.2
      #   env:
      #     SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      #   with:
      #     status: ${{ job.status }}
      #     steps: ${{ toJson(steps) }}
      #     channel: '#cloud-tech'
